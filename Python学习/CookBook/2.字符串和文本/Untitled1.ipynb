{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.19 编写一个简单的递归下降解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
    "                                 DIVIDE, LPAREN, RPAREN, WS]))\n",
    "\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "def genetate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parser\n",
    "class ExpressionEvaluator:\n",
    "    '''\n",
    "    Implementation of a recursive descent parser.Each method\n",
    "    implements a single grammar rule.Use the ._accept() method\n",
    "    to test and accept the current lookahead token. Use the ._expect()\n",
    "    method to exactly match adn discard the next token on on the input\n",
    "    (or raise a SyntaxError if it doesn't match).\n",
    "    '''\n",
    "    \n",
    "    def parse(self, text):\n",
    "        self.tokens = genetate_tokens(text)\n",
    "        self.tok = None              # last symbol consumed\n",
    "        self.nexttok = None          # next symbol tokenized\n",
    "        self._advance()              # Load first lookahead token\n",
    "        return self.expr()\n",
    "    \n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "        \n",
    "    def _accept(self, toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def _expect(self, toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "            \n",
    "    # Grammar rules follow\n",
    "    \n",
    "    def expr(self):\n",
    "        \"expression ::= term{ ('+' | '-') term }*\"\n",
    "        \n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*' | '/' ) factor }*\"\n",
    "        \n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "    \n",
    "    def factor(self):\n",
    "        \"factor ::== NUM | (expr)\"\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER of LPAREN')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ExpressionEvaluator()\n",
    "e.parse('2 + (3 + 4) * 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        如果想做的不只是纯粹的计算，就需要修改ExpressionEvaluator类来实现。\n",
    "        如下实现构建了一棵简单的解析树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExpressionTreeBuilder(ExpressionEvaluator):\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+' | '-') term }\"\n",
    "        \n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval = ('+', exprval, right)\n",
    "            elif op == 'MINUS':\n",
    "                exprval = ('-', exprval, right)\n",
    "            return exprval\n",
    "        \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*' | '/') factor }\"\n",
    "        \n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval = ('*', termval, right)\n",
    "            elif op == 'DIVIDE':\n",
    "                termval = ('/', termval, right)\n",
    "        return termval\n",
    "    \n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | (expr)\"\n",
    "        \n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用ply解析工具解析计算器表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Rule 't_ignored' defined for an unspecified token ignored\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<module '__main__'> is a built-in module",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7709f4ea6cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Build the lexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mlexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Grammar rules and handler functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ply\\lex.py\u001b[0m in \u001b[0;36mlex\u001b[1;34m(module, object, debug, optimize, lextab, reflags, nowarn, outputdir, debuglog, errorlog)\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[0mlinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't build lexer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ply\\lex.py\u001b[0m in \u001b[0;36mvalidate_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_literals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ply\\lex.py\u001b[0m in \u001b[0;36mvalidate_rules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\ply\\lex.py\u001b[0m in \u001b[0;36mvalidate_module\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m             \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsourcelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    923\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    924\u001b[0m     \u001b[0mobject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    736\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;31m# Invalidate cache if needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \"\"\"\n\u001b[1;32m--> 654\u001b[1;33m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__file__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{!r} is a built-in module'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__module__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <module '__main__'> is a built-in module"
     ]
    }
   ],
   "source": [
    "from ply.lex import lex\n",
    "from ply.yacc import yacc\n",
    "\n",
    "# Token list\n",
    "tokens = ['NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN']\n",
    "\n",
    "#Ignored characters\n",
    "\n",
    "t_ignore = ' \\t\\n'\n",
    "\n",
    "# Token specifications( as regexs)\n",
    "t_PLUS = r'\\+'\n",
    "t_MINUS = r'-'\n",
    "t_TIMES = r'\\*'\n",
    "t_DIVIDE = r'/'\n",
    "t_LPAREN = r'\\('\n",
    "t_RPAREN = r'\\)'\n",
    "\n",
    "# Token processing functions\n",
    "def t_NUM(t):\n",
    "    r'\\d+'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    "\n",
    "# Error handler\n",
    "def t_error(t):\n",
    "    print('Bad character: {!r}'.format(t.value[0]))\n",
    "    t.skip(1)\n",
    "    \n",
    "# Build the lexer\n",
    "lexer = lex()\n",
    "\n",
    "# Grammar rules and handler functions\n",
    "def p_expr(p):\n",
    "    \"\"\"\n",
    "    expr: expr PLUS term\n",
    "    | expr MINUS term\n",
    "    \"\"\"\n",
    "    if p[2] == '+':\n",
    "        p[0] = p[1] + p[3]\n",
    "    elif p[2] == '-':\n",
    "        p[0] = p[1] - p[3]\n",
    "        \n",
    "def p_expr_term(p):\n",
    "    '''\n",
    "    expr : term\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_term(p):\n",
    "    \"\"\"\n",
    "    term: term TIMES factor\n",
    "    | term DIVIDE factor\n",
    "    \"\"\"\n",
    "    if p[2] == '*':\n",
    "        p[0] = p[1] * p[3]\n",
    "    elif p[2] == '/':\n",
    "        p[0] == p[1] / p[3]\n",
    "        \n",
    "def p_term_factor(p):\n",
    "    '''\n",
    "    term: factor\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_factor(p):\n",
    "    '''\n",
    "    factor:NUM\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor_group(p):\n",
    "    '''\n",
    "    factor: LPAREN expr RPAREN\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_error(p):\n",
    "    print('Syntax error')\n",
    "    \n",
    "parser = yacc()\n",
    "\n",
    "parser.parse('2+3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.20 在字节串上执行文本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
